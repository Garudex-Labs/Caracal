# Docker Compose configuration for Caracal Core v0.3 - Kafka Infrastructure
# Requirements: 1.7, 25.1, 25.2
#
# This compose file sets up the Kafka event streaming infrastructure:
# - Zookeeper ensemble (3 nodes for high availability)
# - Kafka brokers (3 nodes with replication factor 3)
# - Confluent Schema Registry for Avro schema management
# - TLS encryption and SASL/SCRAM authentication enabled
#
# Usage:
#   # Start Kafka infrastructure
#   docker-compose -f docker-compose.kafka.yml up -d
#
#   # View logs
#   docker-compose -f docker-compose.kafka.yml logs -f
#
#   # Stop all services
#   docker-compose -f docker-compose.kafka.yml down
#
#   # Stop and remove volumes (WARNING: deletes all Kafka data)
#   docker-compose -f docker-compose.kafka.yml down -v
#
# Prerequisites:
#   1. Create ./kafka-certs directory with TLS certificates:
#      - kafka-server.crt, kafka-server.key (for Kafka broker TLS)
#      - ca.crt (CA certificate)
#   2. Create .env file with required environment variables (see .env.example)
#   3. Generate SASL/SCRAM credentials (see scripts/generate-kafka-credentials.sh)

version: '3.8'

services:
  # Zookeeper Node 1
  zookeeper-1:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: caracal-zookeeper-1
    hostname: zookeeper-1
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_SERVERS: zookeeper-1:2888:3888;zookeeper-2:2888:3888;zookeeper-3:2888:3888
    volumes:
      - zookeeper_1_data:/var/lib/zookeeper/data
      - zookeeper_1_log:/var/lib/zookeeper/log
    networks:
      - caracal-kafka-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "bash", "-c", "echo ruok | nc localhost 2181 | grep imok"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Zookeeper Node 2
  zookeeper-2:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: caracal-zookeeper-2
    hostname: zookeeper-2
    environment:
      ZOOKEEPER_SERVER_ID: 2
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_SERVERS: zookeeper-1:2888:3888;zookeeper-2:2888:3888;zookeeper-3:2888:3888
    volumes:
      - zookeeper_2_data:/var/lib/zookeeper/data
      - zookeeper_2_log:/var/lib/zookeeper/log
    networks:
      - caracal-kafka-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "bash", "-c", "echo ruok | nc localhost 2181 | grep imok"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Zookeeper Node 3
  zookeeper-3:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: caracal-zookeeper-3
    hostname: zookeeper-3
    environment:
      ZOOKEEPER_SERVER_ID: 3
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_SERVERS: zookeeper-1:2888:3888;zookeeper-2:2888:3888;zookeeper-3:2888:3888
    volumes:
      - zookeeper_3_data:/var/lib/zookeeper/data
      - zookeeper_3_log:/var/lib/zookeeper/log
    networks:
      - caracal-kafka-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "bash", "-c", "echo ruok | nc localhost 2181 | grep imok"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Kafka Broker 1
  kafka-1:
    image: confluentinc/cp-kafka:7.5.0
    container_name: caracal-kafka-1
    hostname: kafka-1
    depends_on:
      zookeeper-1:
        condition: service_healthy
      zookeeper-2:
        condition: service_healthy
      zookeeper-3:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181
      
      # Listener Configuration
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-1:9092,EXTERNAL://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:SASL_SSL,EXTERNAL:SASL_SSL
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      
      # SASL/SCRAM Authentication
      KAFKA_SASL_ENABLED_MECHANISMS: SCRAM-SHA-512
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-512
      KAFKA_SECURITY_INTER_BROKER_PROTOCOL: SASL_SSL
      
      # TLS Configuration
      KAFKA_SSL_KEYSTORE_FILENAME: kafka.keystore.jks
      KAFKA_SSL_KEYSTORE_CREDENTIALS: keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: key_creds
      KAFKA_SSL_TRUSTSTORE_FILENAME: kafka.truststore.jks
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: truststore_creds
      KAFKA_SSL_CLIENT_AUTH: required
      
      # Replication Configuration
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      
      # Performance Configuration
      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      
      # Log Configuration
      KAFKA_LOG_RETENTION_HOURS: 720  # 30 days
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_COMPRESSION_TYPE: snappy
      
      # Group Coordinator Configuration
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 3000
      
      # Metrics
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 3
      CONFLUENT_METRICS_ENABLE: 'true'
    volumes:
      - kafka_1_data:/var/lib/kafka/data
      - ./kafka-certs:/etc/kafka/secrets:ro
    networks:
      - caracal-kafka-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Kafka Broker 2
  kafka-2:
    image: confluentinc/cp-kafka:7.5.0
    container_name: caracal-kafka-2
    hostname: kafka-2
    depends_on:
      zookeeper-1:
        condition: service_healthy
      zookeeper-2:
        condition: service_healthy
      zookeeper-3:
        condition: service_healthy
    ports:
      - "9094:9092"
      - "9095:9093"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181
      
      # Listener Configuration
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-2:9092,EXTERNAL://localhost:9095
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:SASL_SSL,EXTERNAL:SASL_SSL
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      
      # SASL/SCRAM Authentication
      KAFKA_SASL_ENABLED_MECHANISMS: SCRAM-SHA-512
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-512
      KAFKA_SECURITY_INTER_BROKER_PROTOCOL: SASL_SSL
      
      # TLS Configuration
      KAFKA_SSL_KEYSTORE_FILENAME: kafka.keystore.jks
      KAFKA_SSL_KEYSTORE_CREDENTIALS: keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: key_creds
      KAFKA_SSL_TRUSTSTORE_FILENAME: kafka.truststore.jks
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: truststore_creds
      KAFKA_SSL_CLIENT_AUTH: required
      
      # Replication Configuration
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      
      # Performance Configuration
      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      
      # Log Configuration
      KAFKA_LOG_RETENTION_HOURS: 720  # 30 days
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_COMPRESSION_TYPE: snappy
      
      # Group Coordinator Configuration
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 3000
      
      # Metrics
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 3
      CONFLUENT_METRICS_ENABLE: 'true'
    volumes:
      - kafka_2_data:/var/lib/kafka/data
      - ./kafka-certs:/etc/kafka/secrets:ro
    networks:
      - caracal-kafka-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Kafka Broker 3
  kafka-3:
    image: confluentinc/cp-kafka:7.5.0
    container_name: caracal-kafka-3
    hostname: kafka-3
    depends_on:
      zookeeper-1:
        condition: service_healthy
      zookeeper-2:
        condition: service_healthy
      zookeeper-3:
        condition: service_healthy
    ports:
      - "9096:9092"
      - "9097:9093"
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181
      
      # Listener Configuration
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-3:9092,EXTERNAL://localhost:9097
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:SASL_SSL,EXTERNAL:SASL_SSL
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      
      # SASL/SCRAM Authentication
      KAFKA_SASL_ENABLED_MECHANISMS: SCRAM-SHA-512
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-512
      KAFKA_SECURITY_INTER_BROKER_PROTOCOL: SASL_SSL
      
      # TLS Configuration
      KAFKA_SSL_KEYSTORE_FILENAME: kafka.keystore.jks
      KAFKA_SSL_KEYSTORE_CREDENTIALS: keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: key_creds
      KAFKA_SSL_TRUSTSTORE_FILENAME: kafka.truststore.jks
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: truststore_creds
      KAFKA_SSL_CLIENT_AUTH: required
      
      # Replication Configuration
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      
      # Performance Configuration
      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      
      # Log Configuration
      KAFKA_LOG_RETENTION_HOURS: 720  # 30 days
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_COMPRESSION_TYPE: snappy
      
      # Group Coordinator Configuration
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 3000
      
      # Metrics
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 3
      CONFLUENT_METRICS_ENABLE: 'true'
    volumes:
      - kafka_3_data:/var/lib/kafka/data
      - ./kafka-certs:/etc/kafka/secrets:ro
    networks:
      - caracal-kafka-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Confluent Schema Registry
  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    container_name: caracal-schema-registry
    hostname: schema-registry
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      
      # Security Configuration
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: SASL_SSL
      SCHEMA_REGISTRY_KAFKASTORE_SASL_MECHANISM: SCRAM-SHA-512
      SCHEMA_REGISTRY_KAFKASTORE_SASL_JAAS_CONFIG: 'org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_SCHEMA_REGISTRY_USER:-schema-registry}" password="${KAFKA_SCHEMA_REGISTRY_PASSWORD:-schema-registry-secret}";'
      
      # TLS Configuration
      SCHEMA_REGISTRY_KAFKASTORE_SSL_TRUSTSTORE_LOCATION: /etc/kafka/secrets/kafka.truststore.jks
      SCHEMA_REGISTRY_KAFKASTORE_SSL_TRUSTSTORE_PASSWORD: ${KAFKA_TRUSTSTORE_PASSWORD:-changeit}
      SCHEMA_REGISTRY_KAFKASTORE_SSL_KEYSTORE_LOCATION: /etc/kafka/secrets/kafka.keystore.jks
      SCHEMA_REGISTRY_KAFKASTORE_SSL_KEYSTORE_PASSWORD: ${KAFKA_KEYSTORE_PASSWORD:-changeit}
      SCHEMA_REGISTRY_KAFKASTORE_SSL_KEY_PASSWORD: ${KAFKA_KEY_PASSWORD:-changeit}
      
      # Schema Registry Configuration
      SCHEMA_REGISTRY_SCHEMA_COMPATIBILITY_LEVEL: backward
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC_REPLICATION_FACTOR: 3
    volumes:
      - ./kafka-certs:/etc/kafka/secrets:ro
    networks:
      - caracal-kafka-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s

# Networks
networks:
  caracal-kafka-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.29.0.0/16

# Volumes
volumes:
  zookeeper_1_data:
    driver: local
  zookeeper_1_log:
    driver: local
  zookeeper_2_data:
    driver: local
  zookeeper_2_log:
    driver: local
  zookeeper_3_data:
    driver: local
  zookeeper_3_log:
    driver: local
  kafka_1_data:
    driver: local
  kafka_2_data:
    driver: local
  kafka_3_data:
    driver: local
